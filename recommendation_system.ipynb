{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75badd9",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Last.fm (PyTorch)\n",
    "\n",
    "This notebook reproduces a lightweight matrix factorization recommender for the Last.fm 360k listening history dataset. The sections below mirror Colab cells so you can copy/paste them directly into Google Colab or run locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537494b5",
   "metadata": {},
   "source": [
    "## Colab Cell 1: Setup and Imports\n",
    "\n",
    "Run the following command if you are using Google Colab (skip it if your environment already has the dependencies):\n",
    "\n",
    "```python\n",
    "!pip install torch pandas tqdm requests\n",
    "```\n",
    "\n",
    "Then execute the import cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309e2df",
   "metadata": {},
   "source": [
    "## Colab Cell 2: Last.fm Dataset Loader\n",
    "\n",
    "The dataset class downloads the official Last.fm 360k archive (~543 MB), extracts the TSV with user–artist play counts, maps string identifiers to integer indices, and returns tensors ready for PyTorch. Set `max_rows` to a smaller number if you want a quicker dry run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8135f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastFmDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for the Last.fm 360k implicit feedback data.\"\"\"\n",
    "\n",
    "    URL = 'http://mtg.upf.edu/static/datasets/last.fm/lastfm-dataset-360K.tar.gz'\n",
    "    ARCHIVE_NAME = 'lastfm-dataset-360K.tar.gz'\n",
    "    EXTRACTED_DIR = 'lastfm-dataset-360K'\n",
    "    DATA_FILE = 'usersha1-artmbid-artname-plays.tsv'\n",
    "\n",
    "    def __init__(self, root_dir=None, max_rows=None, min_plays=1):\n",
    "        super().__init__()\n",
    "        self.root_dir = Path(root_dir or os.getcwd())\n",
    "        self.max_rows = max_rows\n",
    "        self.min_plays = min_plays\n",
    "\n",
    "        self._ensure_data_ready()\n",
    "        self.user_ids, self.item_ids, self.ratings = self._load_tensor_data()\n",
    "\n",
    "        self.num_users = int(self.user_ids.max().item()) + 1\n",
    "        self.num_items = int(self.item_ids.max().item()) + 1\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Internal helpers\n",
    "    # ------------------------------------------------------------------\n",
    "    def _ensure_data_ready(self):\n",
    "        archive_path = self.root_dir / self.ARCHIVE_NAME\n",
    "        extracted_path = self.root_dir / self.EXTRACTED_DIR\n",
    "\n",
    "        if extracted_path.exists():\n",
    "            print('Dataset already extracted.')\n",
    "            return\n",
    "\n",
    "        if not archive_path.exists():\n",
    "            self._download_archive(archive_path)\n",
    "\n",
    "        print('Extracting dataset...')\n",
    "        with tarfile.open(archive_path, 'r:gz') as tar_ref:\n",
    "            signature = inspect.signature(tar_ref.extractall)\n",
    "            extract_kwargs = {'path': self.root_dir}\n",
    "            if 'filter' in signature.parameters:\n",
    "                extract_kwargs['filter'] = 'data'\n",
    "            tar_ref.extractall(**extract_kwargs)\n",
    "        print('Extraction complete.')\n",
    "\n",
    "    def _download_archive(self, archive_path):\n",
    "        archive_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print('Downloading Last.fm 360k dataset (approx 543MB)...')\n",
    "        response = requests.get(self.URL, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress = tqdm(total=total_size, unit='B', unit_scale=True, desc=self.ARCHIVE_NAME)\n",
    "\n",
    "        with archive_path.open('wb') as f:\n",
    "            for data in response.iter_content(block_size):\n",
    "                f.write(data)\n",
    "                progress.update(len(data))\n",
    "        progress.close()\n",
    "        print('Download complete.')\n",
    "\n",
    "    def _load_tensor_data(self):\n",
    "        data_path = self.root_dir / self.EXTRACTED_DIR / self.EXTRACTED_DIR / self.DATA_FILE\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f'Missing data file: {data_path}')\n",
    "\n",
    "        print('Loading user-artist interaction data...')\n",
    "        df = pd.read_csv(\n",
    "            data_path,\n",
    "            sep='\t',\n",
    "            header=None,\n",
    "            names=['user_id_raw', 'artist_id_raw', 'artist_name', 'plays'],\n",
    "            on_bad_lines='skip',\n",
    "            encoding='utf-8',\n",
    "            nrows=self.max_rows\n",
    "        )\n",
    "\n",
    "        df = df[df['artist_id_raw'].notna() & (df['artist_id_raw'] != '')]\n",
    "        if self.min_plays > 1:\n",
    "            df = df[df['plays'] >= self.min_plays]\n",
    "\n",
    "        user_codes, user_uniques = pd.factorize(df['user_id_raw'], sort=True)\n",
    "        item_codes, item_uniques = pd.factorize(df['artist_id_raw'], sort=True)\n",
    "\n",
    "        df['user_id_mapped'] = user_codes\n",
    "        df['item_id_mapped'] = item_codes\n",
    "        df['rating_binary'] = 1.0\n",
    "\n",
    "        self.user_index_to_raw = dict(enumerate(user_uniques))\n",
    "        self.item_index_to_raw = dict(enumerate(item_uniques))\n",
    "        self.item_index_to_name = (\n",
    "            df.drop_duplicates('item_id_mapped')\n",
    "              .set_index('item_id_mapped')['artist_name']\n",
    "              .to_dict()\n",
    "        )\n",
    "        self.user_interactions = (\n",
    "            df.groupby('user_id_mapped')['item_id_mapped'].apply(set).to_dict()\n",
    "        )\n",
    "        self.interactions_df = df[['user_id_mapped', 'item_id_mapped', 'plays', 'artist_name']].copy()\n",
    "\n",
    "        user_ids = torch.tensor(df['user_id_mapped'].values, dtype=torch.long)\n",
    "        item_ids = torch.tensor(df['item_id_mapped'].values, dtype=torch.long)\n",
    "        ratings = torch.tensor(df['rating_binary'].values, dtype=torch.float32)\n",
    "\n",
    "        print(f\"Dataset loaded: {len(user_uniques)} users, {len(item_uniques)} artists, {len(df)} interactions.\")\n",
    "        return user_ids, item_ids, ratings\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Dataset protocol\n",
    "    # ------------------------------------------------------------------\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef52761",
   "metadata": {},
   "source": [
    "## Colab Cell 3: Matrix Factorization Model\n",
    "\n",
    "We model the user–item interaction with two embedding tables. The predicted preference is the dot product of user and artist embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c487196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(nn.Module):\n",
    "    \"\"\"Simple matrix factorization (user/item embeddings + dot product).\"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=50):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        nn.init.uniform_(self.user_embedding.weight, -0.01, 0.01)\n",
    "        nn.init.uniform_(self.item_embedding.weight, -0.01, 0.01)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_vecs = self.user_embedding(user_indices)\n",
    "        item_vecs = self.item_embedding(item_indices)\n",
    "        return torch.sum(user_vecs * item_vecs, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c42dfa",
   "metadata": {},
   "source": [
    "## Colab Cell 4: Training Loop\n",
    "\n",
    "We minimise mean squared error against the implicit 1.0 target. For a production system you would typically switch to pairwise ranking losses (BPR) or weighted alternations, but this keeps the demo concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloader, num_users, num_items, embedding_dim=50, epochs=3, learning_rate=0.005, device=DEVICE):\n",
    "    model = CollaborativeFiltering(num_users, num_items, embedding_dim=embedding_dim).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        progress = tqdm(dataloader, desc=f'Epoch {epoch}/{epochs}', leave=False)\n",
    "\n",
    "        for user_idx, item_idx, ratings in progress:\n",
    "            user_idx = user_idx.to(device)\n",
    "            item_idx = item_idx.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_idx, item_idx)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / max(len(dataloader), 1)\n",
    "        print(f'Epoch {epoch} finished. Average loss: {avg_loss:.4f}')\n",
    "\n",
    "    print('Training finished.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7457e",
   "metadata": {},
   "source": [
    "## Colab Cell 5: Train and Generate Recommendations\n",
    "\n",
    "This final cell wires everything together. Adjust `max_rows` if you want to prototype on a subset (e.g., `max_rows=500_000`). After training, we show a random listener’s top plays and new artist recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = None  # Set to a smaller integer for quicker experiments, e.g. 500_000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "EMBEDDING_DIM = 50\n",
    "TOP_K = 10\n",
    "\n",
    "lastfm_dataset = LastFmDataset(max_rows=MAX_ROWS)\n",
    "dataloader = DataLoader(lastfm_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "\n",
    "model = train_model(\n",
    "    dataloader,\n",
    "    lastfm_dataset.num_users,\n",
    "    lastfm_dataset.num_items,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_user_id = torch.randint(0, lastfm_dataset.num_users, (1,), generator=torch.Generator().manual_seed(42)).item()\n",
    "    user_tensor = torch.tensor([sample_user_id], dtype=torch.long, device=DEVICE)\n",
    "    user_embedding = model.user_embedding(user_tensor).squeeze(0)\n",
    "\n",
    "    all_item_ids = torch.arange(lastfm_dataset.num_items, dtype=torch.long, device=DEVICE)\n",
    "    item_embeddings = model.item_embedding(all_item_ids)\n",
    "    scores = torch.matmul(item_embeddings, user_embedding)\n",
    "\n",
    "    known_items = lastfm_dataset.user_interactions.get(sample_user_id, set())\n",
    "    if known_items:\n",
    "        known_idx = torch.tensor(list(known_items), dtype=torch.long, device=DEVICE)\n",
    "        scores[known_idx] = float('-inf')\n",
    "\n",
    "    k = min(TOP_K, lastfm_dataset.num_items - len(known_items))\n",
    "    if k <= 0:\n",
    "        raise ValueError('No unseen items available for recommendation. Try a different user.')\n",
    "\n",
    "    top_scores, top_indices = torch.topk(scores, k)\n",
    "\n",
    "print(f\"\n",
    "Sample recommendations for user index {sample_user_id} (raw ID: {lastfm_dataset.user_index_to_raw.get(sample_user_id)})\n",
    "\")\n",
    "\n",
    "user_history = (\n",
    "    lastfm_dataset.interactions_df[lastfm_dataset.interactions_df['user_id_mapped'] == sample_user_id]\n",
    "    .sort_values('plays', ascending=False)\n",
    ")\n",
    "print('Top listened artists:')\n",
    "print(user_history[['artist_name', 'plays']].head(5).to_string(index=False))\n",
    "\n",
    "print(f\"\n",
    "Top {k} recommended artists:\")\n",
    "for rank, (score, idx) in enumerate(zip(top_scores.tolist(), top_indices.tolist()), start=1):\n",
    "    artist_name = lastfm_dataset.item_index_to_name.get(idx, f'Artist {idx}')\n",
    "    print(f\"{rank:2d}. {artist_name} (score: {score:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
